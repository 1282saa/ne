import streamlit as st
import pandas as pd
import numpy as np
import requests
import json
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import Counter
import os
from dotenv import load_dotenv
import time

# ê°€ì¥ ë¨¼ì € set_page_config í˜¸ì¶œ
st.set_page_config(page_title="ë‰´ìŠ¤ ì´ìŠˆ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë”©
load_dotenv()
API_KEY = os.getenv("BIGKINDS_KEY")

# API í‚¤ ë””ë²„ê¹… - ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸í•˜ê³  ë§ˆìŠ¤í‚¹
if API_KEY:
    masked_key = "â—" * (len(API_KEY) - 4) + API_KEY[-4:] if len(API_KEY) > 4 else "â—â—â—â—"
    st.sidebar.success(f"API í‚¤ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {masked_key}")
else:
    st.error("API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— BIGKINDS_KEYê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œ í™˜ê²½ì— ë§ê²Œ ì ìš©)
try:
    # ë‹¤ì–‘í•œ í•œê¸€ í°íŠ¸ ì˜µì…˜ ì‹œë„
    font_options = ['NanumGothic', 'AppleGothic', 'Gulim', 'Batang', 'Dotum', 'Arial Unicode MS']
    
    # í°íŠ¸ ê°€ìš©ì„± í™•ì¸ ë° ì„¤ì •
    font_found = False
    for font in font_options:
        try:
            plt.rcParams['font.family'] = font
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ í°íŠ¸ í…ŒìŠ¤íŠ¸
            fig, ax = plt.subplots(figsize=(1, 1))
            ax.text(0.5, 0.5, 'í…ŒìŠ¤íŠ¸')
            fig.tight_layout()
            plt.close(fig)  # í…ŒìŠ¤íŠ¸ í›„ ë‹«ê¸°
            font_found = True
            break
        except Exception:
            continue
            
    if not font_found:
        # í°íŠ¸ ì—†ì„ ê²½ìš° ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ í‘œì‹œ ë¬¸ì œ í•´ê²°
        
except Exception as e:
    # í°íŠ¸ ì„¤ì • ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì§„í–‰
    st.warning(f"í°íŠ¸ ì„¤ì • ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
ENDPOINTS = {
    "search_news": "https://tools.kinds.or.kr/search/news",
    "issue_ranking": "https://tools.kinds.or.kr/issue_ranking",
    "word_cloud": "https://tools.kinds.or.kr/word_cloud",
    "time_line": "https://tools.kinds.or.kr/time_line"
}

# API ìš”ì²­ í•¨ìˆ˜
def make_api_request(endpoint, data, debug=False):
    """API ìš”ì²­ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    url = ENDPOINTS.get(endpoint)
    if not url:
        st.error(f"ì—”ë“œí¬ì¸íŠ¸ '{endpoint}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # API í‚¤ ì¶”ê°€
    data["access_key"] = API_KEY
    
    if debug:
        st.write(f"ìš”ì²­ URL: {url}")
        st.write(f"ìš”ì²­ ë°ì´í„°: {json.dumps(data, indent=2, ensure_ascii=False)}")
    
    try:
        response = requests.post(url, json=data, timeout=30)
        
        # ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ ì‘ë‹µ ìƒíƒœë¥¼ í‘œì‹œ
        if debug:
            st.write(f"ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
            st.write(f"ì‘ë‹µ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {response.text[:200]}...")
            st.write(f"ì‘ë‹µ í—¤ë”: {dict(response.headers)}")

        response.raise_for_status()
        
        result = response.json()
        
        if debug:
            st.write(f"ì‘ë‹µ ê²°ê³¼ ì½”ë“œ: {result.get('result')}")
        
        if result.get("result") != 0:
            st.error(f"API ì‘ë‹µ ì˜¤ë¥˜: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            return None
        
        return result.get("return_object")
    except requests.exceptions.RequestException as e:
        st.error(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    except json.JSONDecodeError:
        st.error("ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        if debug:
            st.code(response.text)
        return None
    except Exception as e:
        st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# íƒ€ì´í‹€ ë° ì†Œê°œ
st.title("ğŸ“° ë‰´ìŠ¤ ì´ìŠˆ ë¶„ì„ ì‹œìŠ¤í…œ")
st.write("ë¹…ì¹´ì¸ì¦ˆ APIë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ì´ìŠˆ ìë™ ë¶„ì„ ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    # ë‚ ì§œ ì„ íƒ
    st.header("ğŸ“… ë¶„ì„ ê¸°ê°„ ì„¤ì •")
    today = datetime.now().date()
    date_option = st.radio("ë‚ ì§œ ì„ íƒ ë°©ì‹", ["ì˜¤ëŠ˜", "ì–´ì œ", "íŠ¹ì • ë‚ ì§œ"])
    
    if date_option == "ì˜¤ëŠ˜":
        selected_date = today
    elif date_option == "ì–´ì œ":
        selected_date = today - timedelta(days=1)
    else:
        selected_date = st.date_input("ë¶„ì„í•  ë‚ ì§œ ì„ íƒ", today)
    
    # ë¶„ì„ ê¸°ê°„ ì„¤ì •
    st.header("â±ï¸ ê³¼ê±° ë°ì´í„° ë¶„ì„ ê¸°ê°„")
    days_to_analyze = st.slider("ë¶„ì„ ê¸°ê°„ (ì¼)", 7, 30, 14)
    
    # ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€
    debug_mode = st.checkbox("ë””ë²„ê·¸ ëª¨ë“œ", value=False)

# ë‚ ì§œ í˜•ì‹ ë³€í™˜
date_str = selected_date.strftime("%Y-%m-%d")
date_str_no_dash = date_str.replace("-", "")

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ğŸ“‹ ì˜¤ëŠ˜ì˜ ì´ìŠˆ", "ğŸ” ì´ìŠˆ ë¶„ì„", "ğŸ“Š ê³¼ê±° ë°ì´í„° ë¹„êµ"])

# íƒ­ 1: ì˜¤ëŠ˜ì˜ ì´ìŠˆ
with tab1:
    st.header(f"ğŸ“‹ {date_str} ì£¼ìš” ì´ìŠˆ")
    
    # ì˜¤ëŠ˜ì˜ ì´ìŠˆ API í˜¸ì¶œ (issue_ranking)
    with st.spinner("ì˜¤ëŠ˜ì˜ ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        issue_data = {
            "argument": {
                "date": "2025-04-20",
                "provider": ["02100201"]
            }
        }
        
        issues_result = make_api_request("issue_ranking", issue_data, debug=debug_mode)
        
        if issues_result:
            topics = issues_result.get("topics", [])
            
            if not topics:
                st.warning(f"{date_str}ì— í•´ë‹¹í•˜ëŠ” ì´ìŠˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success(f"{len(topics)}ê°œì˜ ì´ìŠˆë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                
                # ì´ìŠˆ ëª©ë¡ í‘œì‹œ
                for i, issue in enumerate(topics[:10]):  # ìƒìœ„ 10ê°œ ì´ìŠˆë§Œ í‘œì‹œ
                    topic = issue.get("topic", "ì œëª© ì—†ìŒ")
                    topic_rank = issue.get("topic_rank", 0)
                    
                    # ë‰´ìŠ¤ í´ëŸ¬ìŠ¤í„° ID ëª©ë¡
                    news_cluster = issue.get("news_cluster", [])
                    news_count = len(news_cluster)
                    
                    # í‚¤ì›Œë“œ ì¶”ì¶œ ë° í‘œì‹œ
                    keywords = issue.get("topic_keyword", "").split(",")[:10]  # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œë§Œ í‘œì‹œ
                    
                    with st.expander(f"{i+1}. {topic} (ê´€ë ¨ ê¸°ì‚¬: {news_count}ê°œ)"):
                        # í‚¤ì›Œë“œ í‘œì‹œ
                        st.write("**ì£¼ìš” í‚¤ì›Œë“œ:**")
                        st.write(", ".join(keywords))
                        
                        # ê´€ë ¨ ê¸°ì‚¬ ID ëª©ë¡
                        if news_cluster and len(news_cluster) > 0:
                            st.write("**ê´€ë ¨ ê¸°ì‚¬ ë¯¸ë¦¬ë³´ê¸°:**")
                            
                            # ê´€ë ¨ ê¸°ì‚¬ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ 5ê°œë§Œ)
                            with st.spinner("ê´€ë ¨ ê¸°ì‚¬ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                                detail_data = {
                                    "argument": {
                                        "news_ids": news_cluster[:5],
                                        "fields": ["title", "published_at", "provider", "hilight"]
                                    }
                                }
                                
                                news_details_result = make_api_request("search_news", detail_data, debug=debug_mode)
                                
                                if news_details_result:
                                    news_docs = news_details_result.get("documents", [])
                                    
                                    # ê´€ë ¨ ê¸°ì‚¬ í‘œì‹œ
                                    for j, news in enumerate(news_docs):
                                        st.write(f"**{j+1}. {news.get('title', 'ì œëª© ì—†ìŒ')}**")
                                        st.write(f"*ì¶œì²˜: {news.get('provider', 'ì¶œì²˜ ë¯¸ìƒ')} | ë°œí–‰: {news.get('published_at', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')[:10]}*")
                                        if "hilight" in news:
                                            st.write(news.get("hilight", ""))
                                        st.write("---")
                                else:
                                    st.error("ê´€ë ¨ ê¸°ì‚¬ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
                        # ì´ìŠˆ ë¶„ì„ ë²„íŠ¼
                        if st.button(f"ì´ìŠˆ ë¶„ì„í•˜ê¸° #{i+1}", key=f"analyze_issue_{i}"):
                            # ì„¸ì…˜ ìƒíƒœì— ì„ íƒí•œ ì´ìŠˆ ì €ì¥
                            st.session_state.selected_issue = issue
                            st.session_state.selected_issue_index = i
                            # ì´ìŠˆ ë¶„ì„ íƒ­ìœ¼ë¡œ ì´ë™ (URL íŒŒë¼ë¯¸í„° ì‚¬ìš©)
                            st.query_params.tab = "issue_analysis"  # ìˆ˜ì •ëœ ë¶€ë¶„
                            st.rerun()  # ìˆ˜ì •ëœ ë¶€ë¶„
        else:
            st.error("ì˜¤ëŠ˜ì˜ ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# íƒ­ 2: ì´ìŠˆ ë¶„ì„
with tab2:
    st.header("ğŸ” ì´ìŠˆ ìƒì„¸ ë¶„ì„")
    
    # ì„¸ì…˜ ìƒíƒœì—ì„œ ì„ íƒí•œ ì´ìŠˆ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒ
    if "selected_issue" in st.session_state:
        selected_issue = st.session_state.selected_issue
        selected_issue_index = st.session_state.selected_issue_index
    else:
        # ì˜¤ëŠ˜ì˜ ì´ìŠˆ API í˜¸ì¶œ (issue_ranking)
        with st.spinner("ì´ìŠˆ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            issue_data = {
                "argument": {
                    "date": date_str_no_dash,
                    "provider": ["ì„œìš¸ê²½ì œ"]
                }
            }
            
            issues_result = make_api_request("issue_ranking", issue_data, debug=debug_mode)
            
            if issues_result:
                topics = issues_result.get("topics", [])
                
                if not topics:
                    st.warning(f"{date_str}ì— í•´ë‹¹í•˜ëŠ” ì´ìŠˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()
                
                # ì´ìŠˆ ì„ íƒ ë°•ìŠ¤
                issue_titles = [f"{i+1}. {issue.get('topic', 'ì œëª© ì—†ìŒ')}" for i, issue in enumerate(topics)]
                selected_issue_title = st.selectbox("ë¶„ì„í•  ì´ìŠˆ ì„ íƒ", issue_titles)
                
                # ì„ íƒí•œ ì´ìŠˆ ì¸ë±ìŠ¤ ì¶”ì¶œ
                selected_issue_index = issue_titles.index(selected_issue_title)
                selected_issue = topics[selected_issue_index]
            else:
                st.error("ì´ìŠˆ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.stop()
    
    # ì„ íƒí•œ ì´ìŠˆ ì •ë³´ í‘œì‹œ
    st.subheader(f"ì„ íƒí•œ ì´ìŠˆ: {selected_issue.get('topic', 'ì œëª© ì—†ìŒ')}")
    
    # ì´ìŠˆ í‚¤ì›Œë“œ í‘œì‹œ
    keywords = selected_issue.get("topic_keyword", "").split(",")[:15]
    st.write("**ì´ìŠˆ í‚¤ì›Œë“œ:**")
    st.write(", ".join(keywords))
    
    # ì´ìŠˆ ë¶„ì„ ì‹œì‘
    if st.button("ì´ìŠˆ ë¶„ì„ ì‹œì‘", key="start_analysis"):
        with st.spinner("ì´ìŠˆë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘... ì´ ì‘ì—…ì€ ë‹¤ì†Œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
            # ë¶„ì„ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ì„¤ì •
            end_date_obj = selected_date
            start_date_obj = end_date_obj - timedelta(days=7)
            
            start_date_str = start_date_obj.strftime("%Y-%m-%d")
            end_date_str = end_date_obj.strftime("%Y-%m-%d")
            
            # ì´ìŠˆ ë¶„ì„ ì‹¤í–‰
            topic_keywords = selected_issue.get("topic_keyword", "").split(",")
            main_keywords = topic_keywords[:3]  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
            query = " AND ".join(main_keywords)
            
            # ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
            analysis_result = {
                "issue": selected_issue,
                "related_news": [],
                "keywords": [],
                "related_keywords": [],
                "timeline": {},
                "historical_comparison": []
            }
            
            # 1. ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
            search_data = {
                "argument": {
                    "query": query,
                    "published_at": {
                        "from": start_date_str,
                        "until": end_date_str
                    },
                    "provider": ["ì„œìš¸ê²½ì œ"],
                    "sort": {"date": "desc"},
                    "return_from": 0,
                    "return_size": 20,
                    "fields": ["title", "content", "published_at", "provider", "category", "byline", "hilight"]
                }
            }
            
            news_result = make_api_request("search_news", search_data, debug=debug_mode)
            
            if news_result:
                analysis_result["related_news"] = news_result.get("documents", [])
            
            # 2. ì—°ê´€ì–´ ë¶„ì„
            wordcloud_data = {
                "argument": {
                    "query": query,
                    "published_at": {
                        "from": start_date_str,
                        "until": end_date_str
                    },
                    "provider": ["ì„œìš¸ê²½ì œ"]
                }
            }
            
            wordcloud_result = make_api_request("word_cloud", wordcloud_data, debug=debug_mode)
            
            if wordcloud_result:
                analysis_result["related_keywords"] = wordcloud_result.get("nodes", [])
            
            # 3. ì‹œê°„ë³„ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„
            timeline_start = datetime.now() - timedelta(days=days_to_analyze)
            timeline_end = datetime.now()
            
            timeline_data = {
                "argument": {
                    "query": query,
                    "published_at": {
                        "from": timeline_start.strftime("%Y-%m-%d"),
                        "until": timeline_end.strftime("%Y-%m-%d")
                    },
                    "provider": ["ì„œìš¸ê²½ì œ"],
                    "interval": "day",
                    "normalize": "false"
                }
            }
            
            timeline_result = make_api_request("time_line", timeline_data, debug=debug_mode)
            
            if timeline_result:
                analysis_result["timeline"] = timeline_result
            
            # 4. ê³¼ê±° ë°ì´í„° ë¹„êµ (1ì£¼ì¼ ì „, 2ì£¼ì¼ ì „)
            historical_comparison = []
            
            # 1ì£¼ì¼ ì „ ë°ì´í„°
            week_ago_end = datetime.now() - timedelta(days=7)
            week_ago_start = week_ago_end - timedelta(days=7)
            
            week_ago_data = {
                "argument": {
                    "query": query,
                    "published_at": {
                        "from": week_ago_start.strftime("%Y-%m-%d"),
                        "until": week_ago_end.strftime("%Y-%m-%d")
                    },
                    "provider": ["ì„œìš¸ê²½ì œ"],
                    "sort": {"date": "desc"},
                    "return_from": 0,
                    "return_size": 10,
                    "fields": ["title", "published_at", "provider"]
                }
            }
            
            week_ago_result = make_api_request("search_news", week_ago_data, debug=debug_mode)
            
            if week_ago_result:
                historical_comparison.append({
                    "period": "1ì£¼ì¼ ì „",
                    "news": week_ago_result.get("documents", [])
                })
            
            # 2ì£¼ì¼ ì „ ë°ì´í„°
            two_weeks_ago_end = datetime.now() - timedelta(days=14)
            two_weeks_ago_start = two_weeks_ago_end - timedelta(days=7)
            
            two_weeks_ago_data = {
                "argument": {
                    "query": query,
                    "published_at": {
                        "from": two_weeks_ago_start.strftime("%Y-%m-%d"),
                        "until": two_weeks_ago_end.strftime("%Y-%m-%d")
                    },
                    "provider": ["ì„œìš¸ê²½ì œ"],
                    "sort": {"date": "desc"},
                    "return_from": 0,
                    "return_size": 10,
                    "fields": ["title", "published_at", "provider"]
                }
            }
            
            two_weeks_ago_result = make_api_request("search_news", two_weeks_ago_data, debug=debug_mode)
            
            if two_weeks_ago_result:
                historical_comparison.append({
                    "period": "2ì£¼ì¼ ì „",
                    "news": two_weeks_ago_result.get("documents", [])
                })
            
            analysis_result["historical_comparison"] = historical_comparison
            
            # ë¶„ì„ ê²°ê³¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.analysis_result = analysis_result
    
    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if "analysis_result" in st.session_state:
        analysis_result = st.session_state.analysis_result
        
        # ë¶„ì„ ê²°ê³¼ íƒ­ ìƒì„±
        analysis_tab1, analysis_tab2, analysis_tab3 = st.tabs([
            "ğŸ“° ê´€ë ¨ ê¸°ì‚¬", "ğŸ”‘ í‚¤ì›Œë“œ ë¶„ì„", "ğŸ“ˆ ì‹œê°„ë³„ ì¶”ì´"
        ])
        
        # íƒ­ 1: ê´€ë ¨ ê¸°ì‚¬
        with analysis_tab1:
            st.subheader("ê´€ë ¨ ê¸°ì‚¬ ëª©ë¡")
            
            related_news = analysis_result.get("related_news", [])
            
            if not related_news:
                st.info("ê´€ë ¨ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ê¸°ì‚¬ ì •ë ¬ (ìµœì‹ ìˆœ)
                sorted_news = sorted(
                    related_news,
                    key=lambda x: x.get("published_at", ""),
                    reverse=True
                )
                
                # ê´€ë ¨ ê¸°ì‚¬ í‘œì‹œ
                for i, news in enumerate(sorted_news):
                    with st.expander(f"{i+1}. {news.get('title', 'ì œëª© ì—†ìŒ')} ({news.get('provider', 'ì¶œì²˜ ë¯¸ìƒ')})"):
                        # ë°œí–‰ ì •ë³´
                        st.write(f"*ì¶œì²˜: {news.get('provider', 'ì¶œì²˜ ë¯¸ìƒ')} | ë°œí–‰: {news.get('published_at', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')[:10]} | ê¸°ì: {news.get('byline', 'ì •ë³´ ì—†ìŒ')}*")
                        
                        # í•˜ì´ë¼ì´íŠ¸ ë˜ëŠ” ìš”ì•½
                        if "hilight" in news:
                            st.write("**í•˜ì´ë¼ì´íŠ¸:**")
                            st.write(news.get("hilight", ""))
                        
                        # ë‚´ìš© ìš”ì•½
                        if "content" in news:
                            st.write("**ë‚´ìš© ìš”ì•½:**")
                            # ê°„ë‹¨í•œ ìš”ì•½ (ì²« 3ë¬¸ì¥ ë˜ëŠ” ìµœëŒ€ 200ì)
                            content = news.get("content", "")
                            sentences = re.split(r'(?<=[.!?])\s+', content)
                            summary = " ".join(sentences[:3])
                            if len(summary) > 200:
                                summary = summary[:197] + "..."
                            st.write(summary)
                        
                        # ì „ì²´ ë‚´ìš© ë³´ê¸° ì˜µì…˜
                        if "content" in news and st.checkbox(f"ì „ì²´ ë‚´ìš© ë³´ê¸° #{i+1}", key=f"show_content_{i}"):
                            st.write("**ì „ì²´ ë‚´ìš©:**")
                            st.write(news.get("content", ""))
        
        # íƒ­ 2: í‚¤ì›Œë“œ ë¶„ì„
        with analysis_tab2:
            st.subheader("í‚¤ì›Œë“œ ë¶„ì„")
            
            # ì´ìŠˆ í‚¤ì›Œë“œ í‘œì‹œ
            st.write("**ì´ìŠˆ í‚¤ì›Œë“œ:**")
            st.write(", ".join(keywords))
            
            # ì—°ê´€ì–´ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            related_keywords = analysis_result.get("related_keywords", [])
            
            if related_keywords:
                st.write("**ì—°ê´€ì–´ ë¶„ì„ ê²°ê³¼:**")
                
                # ì—°ê´€ì–´ í‘œ í‘œì‹œ
                related_keywords_df = pd.DataFrame([
                    {"í‚¤ì›Œë“œ": item.get("name", ""), "ì¤‘ìš”ë„": round(item.get("weight", 0), 2)}
                    for item in related_keywords
                ])
                
                st.dataframe(related_keywords_df, use_container_width=True)
                
                # ìƒìœ„ í‚¤ì›Œë“œ ë§‰ëŒ€ ì°¨íŠ¸
                st.write("**ìƒìœ„ í‚¤ì›Œë“œ:**")
                top_keywords = related_keywords_df.sort_values(by="ì¤‘ìš”ë„", ascending=False).head(10)
                
                try:
                    fig, ax = plt.subplots(figsize=(10, 6))
                    sns.barplot(data=top_keywords, x="ì¤‘ìš”ë„", y="í‚¤ì›Œë“œ", palette="viridis", ax=ax)
                    plt.title("ìƒìœ„ ì—°ê´€ í‚¤ì›Œë“œ")
                    plt.tight_layout()
                    st.pyplot(fig)
                except Exception as e:
                    st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    # ì°¨íŠ¸ ëŒ€ì‹  í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                    st.write("ìƒìœ„ í‚¤ì›Œë“œ ëª©ë¡:")
                    for _, row in top_keywords.iterrows():
                        st.write(f"- {row['í‚¤ì›Œë“œ']}: {row['ì¤‘ìš”ë„']}")
            else:
                st.info("ì—°ê´€ì–´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # íƒ­ 3: ì‹œê°„ë³„ ì¶”ì´
        with analysis_tab3:
            st.subheader("ì‹œê°„ë³„ í‚¤ì›Œë“œ ì¶”ì´")
            
            timeline_data = analysis_result.get("timeline", {})
            
            if timeline_data and "time_line" in timeline_data and timeline_data["time_line"]:
                # íƒ€ì„ë¼ì¸ ë°ì´í„° í‘œì‹œ
                st.write("**ê¸°ê°„ë³„ ì–¸ê¸‰ íšŸìˆ˜:**")
                
                # ë‚ ì§œ í¬ë§· ë³€í™˜ í•¨ìˆ˜
                def format_date(date_str):
                    if len(date_str) == 8:  # YYYYMMDD
                        return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
                    elif len(date_str) == 6:  # YYYYMM
                        return f"{date_str[:4]}-{date_str[4:]}"
                    else:
                        return date_str
                
                # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° í‘œì‹œ
                timeline_df = pd.DataFrame([
                    {"ë‚ ì§œ": format_date(item.get("label", "")), "ì–¸ê¸‰ íšŸìˆ˜": item.get("hits", 0)}
                    for item in timeline_data["time_line"]
                ])
                
                st.dataframe(timeline_df, use_container_width=True)
                
                # íƒ€ì„ë¼ì¸ ì°¨íŠ¸ ìƒì„± ë° í‘œì‹œ
                st.write("**í‚¤ì›Œë“œ ì¶”ì´ ì°¨íŠ¸:**")
                
                try:
                    # ë‚ ì§œ ë³€í™˜ ë° ì •ë ¬
                    timeline_df["ë‚ ì§œ"] = pd.to_datetime(timeline_df["ë‚ ì§œ"])
                    timeline_df = timeline_df.sort_values(by="ë‚ ì§œ")
                    
                    fig, ax = plt.subplots(figsize=(12, 6))
                    sns.lineplot(data=timeline_df, x="ë‚ ì§œ", y="ì–¸ê¸‰ íšŸìˆ˜", marker="o", ax=ax)
                    
                    # ì°¨íŠ¸ ìŠ¤íƒ€ì¼ ì„¤ì •
                    plt.xticks(rotation=45)
                    plt.title("í‚¤ì›Œë“œ ì–¸ê¸‰ ì¶”ì´")
                    plt.xlabel("ë‚ ì§œ")
                    plt.ylabel("ì–¸ê¸‰ íšŸìˆ˜")
                    plt.tight_layout()
                    
                    st.pyplot(fig)
                except Exception as e:
                    st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    # ì°¨íŠ¸ ëŒ€ì‹  í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                    st.write("ë‚ ì§œë³„ ì–¸ê¸‰ íšŸìˆ˜:")
                    for _, row in timeline_df.iterrows():
                        st.write(f"- {row['ë‚ ì§œ'].strftime('%Y-%m-%d')}: {row['ì–¸ê¸‰ íšŸìˆ˜']}íšŒ")
            else:
                st.info("ì‹œê°„ë³„ ì¶”ì´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# íƒ­ 3: ê³¼ê±° ë°ì´í„° ë¹„êµ
with tab3:
    st.header("ğŸ“Š ê³¼ê±° ë°ì´í„° ë¹„êµ")
    
    # ì„¸ì…˜ ìƒíƒœì—ì„œ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    if "analysis_result" in st.session_state:
        analysis_result = st.session_state.analysis_result
        
        # ê³¼ê±° ë°ì´í„° ë¹„êµ ê²°ê³¼ í‘œì‹œ
        historical_comparison = analysis_result.get("historical_comparison", [])
        
        if historical_comparison:
            for period_data in historical_comparison:
                period = period_data.get("period", "")
                news_list = period_data.get("news", [])
                
                st.subheader(f"{period} ê´€ë ¨ ê¸°ì‚¬ ({len(news_list)}ê°œ)")
                
                if news_list:
                    # ê¸°ì‚¬ ëª©ë¡ í‘œì‹œ
                    for i, news in enumerate(news_list):
                        st.write(f"**{i+1}. {news.get('title', 'ì œëª© ì—†ìŒ')}**")
                        st.write(f"*ì¶œì²˜: {news.get('provider', 'ì¶œì²˜ ë¯¸ìƒ')} | ë°œí–‰: {news.get('published_at', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')[:10]}*")
                        st.write("---")
                else:
                    st.info(f"{period}ì— ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ê³¼ê±° ë°ì´í„° ë¹„êµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì´ìŠˆë¥¼ ë¨¼ì € ë¶„ì„í•´ì£¼ì„¸ìš”. 'ì´ìŠˆ ë¶„ì„' íƒ­ì—ì„œ ì´ìŠˆë¥¼ ì„ íƒí•˜ê³  ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")

# í‘¸í„°
st.markdown("---")
st.caption("Â© 2025 ë‰´ìŠ¤ ì´ìŠˆ ë¶„ì„ ì‹œìŠ¤í…œ | ë¹…ì¹´ì¸ì¦ˆ API ê¸°ë°˜")