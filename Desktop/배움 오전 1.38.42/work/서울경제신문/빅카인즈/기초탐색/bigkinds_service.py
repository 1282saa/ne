import streamlit as st
import pandas as pd
import numpy as np
import requests
import json
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
from wordcloud import WordCloud
import matplotlib.font_manager as fm
from collections import Counter
import re
from PIL import Image
import io
import base64

# í•œê¸€ í°íŠ¸ ì„¤ì • (ë§¥/ìœˆë„ìš°/ë¦¬ëˆ…ìŠ¤ í™˜ê²½ì— ë”°ë¼ ì ì ˆíˆ ìˆ˜ì • í•„ìš”)
plt.rcParams['font.family'] = 'Malgun Gothic'  # ìœˆë„ìš°ì˜ ê²½ìš°
# plt.rcParams['font.family'] = 'AppleGothic'  # ë§¥ì˜ ê²½ìš°

class BigKindsAPI:
    """ë¹…ì¹´ì¸ì¦ˆ API í˜¸ì¶œì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, access_key):
        """
        API í‚¤ë¡œ ì´ˆê¸°í™”
        
        Args:
            access_key (str): ë¹…ì¹´ì¸ì¦ˆ API ì ‘ê·¼ í‚¤
        """
        self.access_key = access_key
        self.base_url = "https://tools.kinds.or.kr"
        self.headers = {
            "Content-Type": "application/json"
        }
    
    def _make_request(self, endpoint, data):
        """
        API ìš”ì²­ì„ ìˆ˜í–‰í•˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ
        
        Args:
            endpoint (str): API ì—”ë“œí¬ì¸íŠ¸
            data (dict): ìš”ì²­ ë°ì´í„°
            
        Returns:
            dict: ì‘ë‹µ ë°ì´í„°
        """
        url = f"{self.base_url}/{endpoint}"
        data["access_key"] = self.access_key
        
        try:
            response = requests.post(url, headers=self.headers, json=data)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            st.error(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {"result": -1, "return_object": {}}
    
    def get_issues(self, date=None, providers=None):
        """
        ì˜¤ëŠ˜ì˜ ì´ìŠˆ(ì´ìŠˆ ë­í‚¹) APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì£¼ìš” ì´ìŠˆ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            date (str): ì´ìŠˆë¥¼ ì¡°íšŒí•  ë‚ ì§œ (YYYY-MM-DD)
            providers (list): ì–¸ë¡ ì‚¬ ëª©ë¡
            
        Returns:
            list: ì´ìŠˆ ëª©ë¡
        """
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d")
        
        data = {
            "argument": {
                "date": date.replace("-", "")
            }
        }
        
        if providers:
            data["argument"]["provider"] = providers
        
        response = self._make_request("issue_ranking", data)
        
        if response["result"] == 0:
            return response["return_object"]["topics"]
        else:
            st.error("ì´ìŠˆ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return []
    
    def search_news(self, query=None, start_date=None, end_date=None, providers=None, 
                   categories=None, incident_categories=None, byline=None, 
                   sort=None, return_from=0, return_size=10, fields=None):
        """
        ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬
            start_date (str): ê²€ìƒ‰ ì‹œì‘ì¼ (YYYY-MM-DD)
            end_date (str): ê²€ìƒ‰ ì¢…ë£Œì¼ (YYYY-MM-DD)
            providers (list): ì–¸ë¡ ì‚¬ ëª©ë¡
            categories (list): ë‰´ìŠ¤ ë¶„ë¥˜ ëª©ë¡
            incident_categories (list): ì‚¬ê±´/ì‚¬ê³  ë¶„ë¥˜ ëª©ë¡
            byline (str): ê¸°ì ì´ë¦„
            sort (dict): ì •ë ¬ ì¡°ê±´
            return_from (int): ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜
            return_size (int): ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            fields (list): ë°˜í™˜í•  í•„ë“œ ëª©ë¡
            
        Returns:
            dict: ê²€ìƒ‰ ê²°ê³¼
        """
        data = {
            "argument": {
                "return_from": return_from,
                "return_size": return_size
            }
        }
        
        if fields:
            data["argument"]["fields"] = fields
        else:
            data["argument"]["fields"] = ["title", "content", "published_at", "provider", "byline"]
        
        if query:
            data["argument"]["query"] = query
        
        if start_date and end_date:
            data["argument"]["published_at"] = {
                "from": start_date,
                "until": end_date
            }
        
        if providers:
            data["argument"]["provider"] = providers
        
        if categories:
            data["argument"]["category"] = categories
        
        if incident_categories:
            data["argument"]["category_incident"] = incident_categories
        
        if byline:
            data["argument"]["byline"] = byline
        
        if sort:
            data["argument"]["sort"] = sort
        else:
            data["argument"]["sort"] = {"date": "desc"}
        
        if "hilight" not in data["argument"]:
            data["argument"]["hilight"] = 200
        
        response = self._make_request("search/news", data)
        
        if response["result"] == 0:
            return response["return_object"]
        else:
            st.error("ë‰´ìŠ¤ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return {"total_hits": 0, "documents": []}
    
    def get_news_detail(self, news_ids, fields=None):
        """
        ë‰´ìŠ¤ ì¡°íšŒ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì§€ì •í•œ ë‰´ìŠ¤ì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            news_ids (list): ë‰´ìŠ¤ ID ëª©ë¡
            fields (list): ë°˜í™˜í•  í•„ë“œ ëª©ë¡
            
        Returns:
            dict: ë‰´ìŠ¤ ìƒì„¸ ì •ë³´
        """
        data = {
            "argument": {
                "news_ids": news_ids
            }
        }
        
        if fields:
            data["argument"]["fields"] = fields
        else:
            data["argument"]["fields"] = ["title", "content", "published_at", "provider", "byline", "category", "category_incident"]
        
        response = self._make_request("search/news", data)
        
        if response["result"] == 0:
            return response["return_object"]
        else:
            st.error("ë‰´ìŠ¤ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return {"total_hits": 0, "documents": []}
    
    def get_word_cloud(self, query, start_date=None, end_date=None, providers=None, 
                      categories=None, incident_categories=None, byline=None):
        """
        ì—°ê´€ì–´ ë¶„ì„(ì›Œë“œ í´ë¼ìš°ë“œ) APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì—°ê´€ í‚¤ì›Œë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬
            start_date (str): ê²€ìƒ‰ ì‹œì‘ì¼ (YYYY-MM-DD)
            end_date (str): ê²€ìƒ‰ ì¢…ë£Œì¼ (YYYY-MM-DD)
            providers (list): ì–¸ë¡ ì‚¬ ëª©ë¡
            categories (list): ë‰´ìŠ¤ ë¶„ë¥˜ ëª©ë¡
            incident_categories (list): ì‚¬ê±´/ì‚¬ê³  ë¶„ë¥˜ ëª©ë¡
            byline (str): ê¸°ì ì´ë¦„
            
        Returns:
            list: ì—°ê´€ í‚¤ì›Œë“œ ëª©ë¡
        """
        data = {
            "argument": {
                "query": query
            }
        }
        
        if start_date and end_date:
            data["argument"]["published_at"] = {
                "from": start_date,
                "until": end_date
            }
        
        if providers:
            data["argument"]["provider"] = providers
        
        if categories:
            data["argument"]["category"] = categories
        
        if incident_categories:
            data["argument"]["category_incident"] = incident_categories
        
        if byline:
            data["argument"]["byline"] = byline
        
        response = self._make_request("word_cloud", data)
        
        if response["result"] == 0:
            return response["return_object"]["nodes"]
        else:
            st.error("ì—°ê´€ì–´ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return []
    
    def get_time_line(self, query, start_date=None, end_date=None, providers=None, 
                     categories=None, incident_categories=None, byline=None, 
                     interval="day", normalize=False):
        """
        í‚¤ì›Œë“œ íŠ¸ë Œë“œ(ë‰´ìŠ¤ íƒ€ì„ë¼ì¸) APIë¥¼ í˜¸ì¶œí•˜ì—¬ í‚¤ì›Œë“œ íŠ¸ë Œë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬
            start_date (str): ê²€ìƒ‰ ì‹œì‘ì¼ (YYYY-MM-DD)
            end_date (str): ê²€ìƒ‰ ì¢…ë£Œì¼ (YYYY-MM-DD)
            providers (list): ì–¸ë¡ ì‚¬ ëª©ë¡
            categories (list): ë‰´ìŠ¤ ë¶„ë¥˜ ëª©ë¡
            incident_categories (list): ì‚¬ê±´/ì‚¬ê³  ë¶„ë¥˜ ëª©ë¡
            byline (str): ê¸°ì ì´ë¦„
            interval (str): ì§‘ê³„ ê°„ê²© (day, month, year)
            normalize (bool): ì •ê·œí™” ì—¬ë¶€
            
        Returns:
            dict: í‚¤ì›Œë“œ íŠ¸ë Œë“œ
        """
        data = {
            "argument": {
                "query": query,
                "interval": interval,
                "normalize": str(normalize).lower()
            }
        }
        
        if start_date and end_date:
            data["argument"]["published_at"] = {
                "from": start_date,
                "until": end_date
            }
        
        if providers:
            data["argument"]["provider"] = providers
        
        if categories:
            data["argument"]["category"] = categories
        
        if incident_categories:
            data["argument"]["category_incident"] = incident_categories
        
        if byline:
            data["argument"]["byline"] = byline
        
        response = self._make_request("time_line", data)
        
        if response["result"] == 0:
            return response["return_object"]
        else:
            st.error("í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return {"total_hits": 0, "time_line": []}
    
    def extract_keywords(self, title=None, subtitle=None, content=None):
        """
        í‚¤ì›Œë“œ ì¶”ì¶œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            title (str): ì œëª©
            subtitle (str): ë¶€ì œëª©
            content (str): ë³¸ë¬¸
            
        Returns:
            dict: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        """
        data = {
            "argument": {}
        }
        
        if title:
            data["argument"]["title"] = title
        
        if subtitle:
            data["argument"]["sub_title"] = subtitle
        
        if content:
            data["argument"]["content"] = content
        
        response = self._make_request("keyword", data)
        
        if response["result"] == 0:
            return response["return_object"]["result"]
        else:
            st.error("í‚¤ì›Œë“œ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return {"title": "", "sub_title": "", "content": ""}
    
    def extract_features(self, title=None, subtitle=None, content=None):
        """
        íŠ¹ì„± ì¶”ì¶œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì„±ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            title (str): ì œëª©
            subtitle (str): ë¶€ì œëª©
            content (str): ë³¸ë¬¸
            
        Returns:
            dict: ì¶”ì¶œëœ íŠ¹ì„±
        """
        data = {
            "argument": {}
        }
        
        if title:
            data["argument"]["title"] = title
        
        if subtitle:
            data["argument"]["sub_title"] = subtitle
        
        if content:
            data["argument"]["content"] = content
        
        response = self._make_request("feature", data)
        
        if response["result"] == 0:
            return response["return_object"]["result"]
        else:
            st.error("íŠ¹ì„± ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return {"title": "", "sub_title": "", "content": ""}

class NewsAnalysisSystem:
    """ë‰´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ í´ë˜ìŠ¤"""
    
    def __init__(self, api):
        """
        API ê°ì²´ë¡œ ì´ˆê¸°í™”
        
        Args:
            api (BigKindsAPI): BigKindsAPI ê°ì²´
        """
        self.api = api
    
    def analyze_issue(self, issue, start_date=None, end_date=None, days_to_analyze=14):
        """
        ì´ìŠˆë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            issue (dict): ë¶„ì„í•  ì´ìŠˆ
            start_date (str): ë¶„ì„ ì‹œì‘ì¼
            end_date (str): ë¶„ì„ ì¢…ë£Œì¼
            days_to_analyze (int): ê³¼ê±° ëª‡ ì¼ì¹˜ë¥¼ ë¶„ì„í• ì§€ ì„¤ì •
            
        Returns:
            dict: ì´ìŠˆ ë¶„ì„ ê²°ê³¼
        """
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
        analysis_result = {
            "issue": issue,
            "related_news": [],
            "keywords": [],
            "wordcloud": [],
            "timeline": [],
            "historical_comparison": []
        }
        
        # ë¶„ì„ ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        if not start_date:
            end_date_obj = datetime.now()
            start_date_obj = end_date_obj - timedelta(days=7)
            
            start_date = start_date_obj.strftime("%Y-%m-%d")
            end_date = end_date_obj.strftime("%Y-%m-%d")
        
        # 1. ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
        topic_keywords = issue.get("topic_keyword", "").split(",")
        main_keywords = topic_keywords[:3]  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
        query = " AND ".join(main_keywords)
        
        news_result = self.api.search_news(
            query=query,
            start_date=start_date,
            end_date=end_date,
            return_size=20,
            fields=["title", "content", "published_at", "provider", "category", "byline", "hilight"]
        )
        
        analysis_result["related_news"] = news_result["documents"]
        
        # 2. ëª¨ë“  ê´€ë ¨ ë‰´ìŠ¤ì˜ ë³¸ë¬¸ì„ í•©ì³ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        combined_content = ""
        for news in analysis_result["related_news"]:
            if "content" in news:
                combined_content += news["content"] + " "
        
        if combined_content:
            extracted_keywords = self.api.extract_keywords(content=combined_content)
            if extracted_keywords and "content" in extracted_keywords:
                analysis_result["keywords"] = [kw.strip() for kw in extracted_keywords["content"].split()]
        
        # 3. ì—°ê´€ì–´ ë¶„ì„
        wordcloud_result = self.api.get_word_cloud(
            query=query,
            start_date=start_date,
            end_date=end_date
        )
        
        analysis_result["wordcloud"] = wordcloud_result
        
        # 4. ì‹œê°„ë³„ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„
        # í˜„ì¬ë¶€í„° ì§€ì •ëœ ì¼ìˆ˜ë§Œí¼ ì´ì „ê¹Œì§€ì˜ ë°ì´í„° ë¶„ì„
        timeline_end = datetime.now()
        timeline_start = timeline_end - timedelta(days=days_to_analyze)
        
        timeline_result = self.api.get_time_line(
            query=query,
            start_date=timeline_start.strftime("%Y-%m-%d"),
            end_date=timeline_end.strftime("%Y-%m-%d"),
            interval="day"
        )
        
        analysis_result["timeline"] = timeline_result
        
        # 5. ê³¼ê±° ë°ì´í„° ë¹„êµ (1ì£¼ì¼ ì „, 2ì£¼ì¼ ì „)
        historical_comparison = []
        
        # 1ì£¼ì¼ ì „ ë°ì´í„°
        week_ago_end = datetime.now() - timedelta(days=7)
        week_ago_start = week_ago_end - timedelta(days=7)
        
        week_ago_result = self.api.search_news(
            query=query,
            start_date=week_ago_start.strftime("%Y-%m-%d"),
            end_date=week_ago_end.strftime("%Y-%m-%d"),
            return_size=10,
            fields=["title", "published_at", "provider"]
        )
        
        historical_comparison.append({
            "period": "1ì£¼ì¼ ì „",
            "news": week_ago_result["documents"]
        })
        
        # 2ì£¼ì¼ ì „ ë°ì´í„°
        two_weeks_ago_end = datetime.now() - timedelta(days=14)
        two_weeks_ago_start = two_weeks_ago_end - timedelta(days=7)
        
        two_weeks_ago_result = self.api.search_news(
            query=query,
            start_date=two_weeks_ago_start.strftime("%Y-%m-%d"),
            end_date=two_weeks_ago_end.strftime("%Y-%m-%d"),
            return_size=10,
            fields=["title", "published_at", "provider"]
        )
        
        historical_comparison.append({
            "period": "2ì£¼ì¼ ì „",
            "news": two_weeks_ago_result["documents"]
        })
        
        analysis_result["historical_comparison"] = historical_comparison
        
        return analysis_result
    
    def cluster_news(self, news_list, num_clusters=5):
        """
        ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•©ë‹ˆë‹¤. (ë‹¨ìˆœ í‚¤ì›Œë“œ ê¸°ë°˜)
        
        Args:
            news_list (list): ë‰´ìŠ¤ ê¸°ì‚¬ ëª©ë¡
            num_clusters (int): í´ëŸ¬ìŠ¤í„° ìˆ˜
            
        Returns:
            dict: í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼
        """
        if not news_list:
            return {}
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§
        clusters = {}
        
        # ê° ê¸°ì‚¬ì˜ í‚¤ì›Œë“œ ì¶”ì¶œ
        for news in news_list:
            title = news.get("title", "")
            content = news.get("content", "")
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            extracted = self.api.extract_keywords(title=title, content=content)
            
            # ê°€ì¥ ì¤‘ìš”í•œ í‚¤ì›Œë“œ ì„ íƒ
            main_keyword = None
            if extracted and "content" in extracted:
                keywords = extracted["content"].split()
                if keywords:
                    main_keyword = keywords[0]
            
            if not main_keyword:
                main_keyword = "ê¸°íƒ€"
            
            # í´ëŸ¬ìŠ¤í„°ì— ê¸°ì‚¬ ì¶”ê°€
            if main_keyword not in clusters:
                clusters[main_keyword] = []
            
            clusters[main_keyword].append(news)
        
        # ë„ˆë¬´ ë§ì€ í´ëŸ¬ìŠ¤í„°ê°€ ìƒê¸°ë©´ ê°€ì¥ ê¸°ì‚¬ê°€ ë§ì€ í´ëŸ¬ìŠ¤í„°ë§Œ ì„ íƒ
        if len(clusters) > num_clusters:
            clusters = dict(sorted(clusters.items(), key=lambda x: len(x[1]), reverse=True)[:num_clusters])
        
        return clusters
    
    def create_wordcloud_image(self, words_with_weights):
        """
        ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            words_with_weights (list): (ë‹¨ì–´, ê°€ì¤‘ì¹˜) íŠœí”Œ ëª©ë¡
            
        Returns:
            Image: ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€
        """
        # ë‹¨ì–´ì™€ ê°€ì¤‘ì¹˜ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        word_freq = {}
        
        if isinstance(words_with_weights, list):
            for item in words_with_weights:
                if isinstance(item, dict) and "name" in item and "weight" in item:
                    word = item["name"]
                    weight = item["weight"]
                    word_freq[word] = weight
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if not word_freq:
            word_freq = {"ë°ì´í„°": 1, "ì—†ìŒ": 1}
        
        # ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„±
        wordcloud = WordCloud(
            width=800,
            height=400,
            background_color='white',
            font_path='malgun',  # í•œê¸€ í°íŠ¸ ê²½ë¡œ ì„¤ì • í•„ìš”
            max_words=100,
            max_font_size=200,
            random_state=42
        ).generate_from_frequencies(word_freq)
        
        return wordcloud
    
    def create_timeline_chart(self, timeline_data):
        """
        íƒ€ì„ë¼ì¸ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            timeline_data (dict): íƒ€ì„ë¼ì¸ ë°ì´í„°
            
        Returns:
            plt.Figure: íƒ€ì„ë¼ì¸ ì°¨íŠ¸
        """
        # íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ì°¨íŠ¸ ë°˜í™˜
        if not timeline_data or "time_line" not in timeline_data or not timeline_data["time_line"]:
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.text(0.5, 0.5, "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", ha='center', va='center')
            return fig
        
        # ë°ì´í„° í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(timeline_data["time_line"])
        
        # ë‚ ì§œ í¬ë§· ë³€í™˜ (YYYYMMDD ë˜ëŠ” YYYYMM í˜•ì‹)
        df['date'] = df['label'].apply(self._format_date)
        
        # ì •ë ¬
        df = df.sort_values('date')
        
        # ì°¨íŠ¸ ìƒì„±
        fig, ax = plt.subplots(figsize=(12, 6))
        sns.lineplot(data=df, x='date', y='hits', marker='o', ax=ax)
        
        # ì°¨íŠ¸ ìŠ¤íƒ€ì¼ ì„¤ì •
        plt.xticks(rotation=45)
        plt.title('í‚¤ì›Œë“œ ì–¸ê¸‰ ì¶”ì´')
        plt.xlabel('ë‚ ì§œ')
        plt.ylabel('ì–¸ê¸‰ íšŸìˆ˜')
        plt.tight_layout()
        
        return fig
    
    def _format_date(self, date_str):
        """
        ë‚ ì§œ ë¬¸ìì—´ì„ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
        
        Args:
            date_str (str): ë‚ ì§œ ë¬¸ìì—´ (YYYYMMDD ë˜ëŠ” YYYYMM)
            
        Returns:
            str: í¬ë§·íŒ…ëœ ë‚ ì§œ ë¬¸ìì—´
        """
        if len(date_str) == 8:  # YYYYMMDD
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
        elif len(date_str) == 6:  # YYYYMM
            return f"{date_str[:4]}-{date_str[4:]}"
        else:
            return date_str
    
    def summarize_article(self, content, max_length=200):
        """
        ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤. (ê°„ë‹¨í•œ ë°©ì‹)
        
        Args:
            content (str): ê¸°ì‚¬ ë‚´ìš©
            max_length (int): ìµœëŒ€ ê¸¸ì´
            
        Returns:
            str: ìš”ì•½ëœ ë‚´ìš©
        """
        # ì‹¤ì œë¡œëŠ” AI ìš”ì•½ API ë“±ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì§€ë§Œ,
        # ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„
        if not content:
            return ""
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = re.split(r'(?<=[.!?])\s+', content)
        
        # ì²« ëª‡ ë¬¸ì¥ë§Œ ì„ íƒ
        summary = " ".join(sentences[:3])
        
        # ê¸¸ì´ ì œí•œ
        if len(summary) > max_length:
            summary = summary[:max_length-3] + "..."
        
        return summary

# Streamlit ì•± ìƒì„±
def main():
    st.set_page_config(page_title="ë‰´ìŠ¤ ì´ìŠˆ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")
    
    # íƒ€ì´í‹€ ë° ì†Œê°œ
    st.title("ğŸ“° ë‰´ìŠ¤ ì´ìŠˆ ë¶„ì„ ì‹œìŠ¤í…œ")
    st.write("ë¹…ì¹´ì¸ì¦ˆ APIë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ì´ìŠˆ ìë™ ë¶„ì„ ì‹œìŠ¤í…œ")
    
    # API í‚¤ ì…ë ¥
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        api_key = st.text_input("API í‚¤", type="password")
        
        # ë‚ ì§œ ì„ íƒ
        st.header("ğŸ“… ë¶„ì„ ê¸°ê°„ ì„¤ì •")
        today = datetime.now().date()
        date_option = st.radio("ë‚ ì§œ ì„ íƒ ë°©ì‹", ["ì˜¤ëŠ˜", "ì–´ì œ", "íŠ¹ì • ë‚ ì§œ"])
        
        if date_option == "ì˜¤ëŠ˜":
            selected_date = today
        elif date_option == "ì–´ì œ":
            selected_date = today - timedelta(days=1)
        else:
            selected_date = st.date_input("ë¶„ì„í•  ë‚ ì§œ ì„ íƒ", today)
        
        # ë¶„ì„ ê¸°ê°„ ì„¤ì •
        st.header("â±ï¸ ê³¼ê±° ë°ì´í„° ë¶„ì„ ê¸°ê°„")
        days_to_analyze = st.slider("ë¶„ì„ ê¸°ê°„ (ì¼)", 7, 30, 14)
        
        # ì–¸ë¡ ì‚¬ ì„ íƒ
        st.header("ğŸ“° ì–¸ë¡ ì‚¬ í•„í„°")
        all_providers = ["ê²½í–¥ì‹ ë¬¸", "êµ­ë¯¼ì¼ë³´", "ë‚´ì¼ì‹ ë¬¸", "ë™ì•„ì¼ë³´", "ë¬¸í™”ì¼ë³´", "ì„œìš¸ì‹ ë¬¸", 
                        "ì„¸ê³„ì¼ë³´", "ì¡°ì„ ì¼ë³´", "ì¤‘ì•™ì¼ë³´", "í•œê²¨ë ˆ", "í•œêµ­ì¼ë³´"]
        selected_providers = st.multiselect("ì–¸ë¡ ì‚¬ ì„ íƒ", all_providers)
    
    # API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ì„ ê²½ìš°
    if not api_key:
        st.warning("ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # API ì´ˆê¸°í™”
    try:
        api = BigKindsAPI(api_key)
        news_system = NewsAnalysisSystem(api)
    except Exception as e:
        st.error(f"API ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.stop()
    
    # ë‚ ì§œ í˜•ì‹ ë³€í™˜
    date_str = selected_date.strftime("%Y-%m-%d")
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ ì˜¤ëŠ˜ì˜ ì´ìŠˆ", "ğŸ” ì´ìŠˆ ë¶„ì„", "ğŸ“Š ê³¼ê±° ë°ì´í„° ë¹„êµ"])
    
    # íƒ­ 1: ì˜¤ëŠ˜ì˜ ì´ìŠˆ
    with tab1:
        st.header(f"ğŸ“‹ {date_str} ì£¼ìš” ì´ìŠˆ")
        
        with st.spinner("ì˜¤ëŠ˜ì˜ ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            issues = api.get_issues(date=date_str, providers=selected_providers)
        
        if not issues:
            st.warning(f"{date_str}ì— í•´ë‹¹í•˜ëŠ” ì´ìŠˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ì´ìŠˆ ëª©ë¡ í‘œì‹œ
            for i, issue in enumerate(issues[:10]):  # ìƒìœ„ 10ê°œ ì´ìŠˆë§Œ í‘œì‹œ
                topic = issue.get("topic", "ì œëª© ì—†ìŒ")
                rank = issue.get("topic_rank", 0)
                
                # ë‰´ìŠ¤ í´ëŸ¬ìŠ¤í„° ID ëª©ë¡
                news_cluster = issue.get("news_cluster", [])
                news_count = len(news_cluster)
                
                # í‚¤ì›Œë“œ ì¶”ì¶œ ë° í‘œì‹œ
                keywords = issue.get("topic_keyword", "").split(",")[:10]  # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œë§Œ í‘œì‹œ
                
                with st.expander(f"{i+1}. {topic} (ê´€ë ¨ ê¸°ì‚¬: {news_count}ê°œ)"):
                    # í‚¤ì›Œë“œ í‘œì‹œ
                    st.write("**ì£¼ìš” í‚¤ì›Œë“œ:**")
                    st.write(", ".join(keywords))
                    
                    # ê´€ë ¨ ê¸°ì‚¬ ID ëª©ë¡
                    if news_cluster:
                        st.write("**ê´€ë ¨ ê¸°ì‚¬ ë¯¸ë¦¬ë³´ê¸°:**")
                        
                        # ê´€ë ¨ ê¸°ì‚¬ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ 5ê°œë§Œ)
                        with st.spinner("ê´€ë ¨ ê¸°ì‚¬ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                            news_details = api.get_news_detail(
                                news_ids=news_cluster[:5],
                                fields=["title", "published_at", "provider", "hilight"]
                            )
                        
                        # ê´€ë ¨ ê¸°ì‚¬ í‘œì‹œ
                        for j, news in enumerate(news_details.get("documents", [])):
                            st.write(f"**{j+1}. {news.get('title', 'ì œëª© ì—†ìŒ')}**")
                            st.write(f"*ì¶œì²˜: {news.get('provider', 'ì¶œì²˜ ë¯¸ìƒ')} | ë°œí–‰: {news.get('published_at', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')[:10]}*")
                            if "hilight" in news:
                                st.write(news.get("hilight", ""))
                            st.write("---")
                    
                    # ì´ìŠˆ ë¶„ì„ ë²„íŠ¼
                    if st.button(f"ì´ìŠˆ ë¶„ì„í•˜ê¸° #{i+1}", key=f"analyze_issue_{i}"):
                        # ì„¸ì…˜ ìƒíƒœì— ì„ íƒí•œ ì´ìŠˆ ì €ì¥
                        st.session_state.selected_issue = issue
                        st.session_state.selected_issue_index = i
                        # ì´ìŠˆ ë¶„ì„ íƒ­ìœ¼ë¡œ ì´ë™
                        st.experimental_set_query_params(tab="issue_analysis")
                        st.experimental_rerun()
    
    # íƒ­ 2: ì´ìŠˆ ë¶„ì„
    with tab2:
        st.header("ğŸ” ì´ìŠˆ ìƒì„¸ ë¶„ì„")
        
        # ì„¸ì…˜ ìƒíƒœì—ì„œ ì„ íƒí•œ ì´ìŠˆ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒ
        if "selected_issue" in st.session_state:
            selected_issue = st.session_state.selected_issue
            selected_issue_index = st.session_state.selected_issue_index
        else:
            # ì´ìŠˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            with st.spinner("ì´ìŠˆ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                issues = api.get_issues(date=date_str, providers=selected_providers)
            
            if not issues:
                st.warning(f"{date_str}ì— í•´ë‹¹í•˜ëŠ” ì´ìŠˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
            
            # ì´ìŠˆ ì„ íƒ ë°•ìŠ¤
            issue_titles = [f"{i+1}. {issue.get('topic', 'ì œëª© ì—†ìŒ')}" for i, issue in enumerate(issues)]
            selected_issue_title = st.selectbox("ë¶„ì„í•  ì´ìŠˆ ì„ íƒ", issue_titles)
            
            # ì„ íƒí•œ ì´ìŠˆ ì¸ë±ìŠ¤ ì¶”ì¶œ
            selected_issue_index = issue_titles.index(selected_issue_title)
            selected_issue = issues[selected_issue_index]
        
        # ì„ íƒí•œ ì´ìŠˆ ì •ë³´ í‘œì‹œ
        st.subheader(f"ì„ íƒí•œ ì´ìŠˆ: {selected_issue.get('topic', 'ì œëª© ì—†ìŒ')}")
        
        # ì´ìŠˆ í‚¤ì›Œë“œ í‘œì‹œ
        keywords = selected_issue.get("topic_keyword", "").split(",")[:15]
        st.write("**ì´ìŠˆ í‚¤ì›Œë“œ:**")
        st.write(", ".join(keywords))
        
        # ì´ìŠˆ ë¶„ì„ ì‹œì‘
        if st.button("ì´ìŠˆ ë¶„ì„ ì‹œì‘", key="start_analysis"):
            with st.spinner("ì´ìŠˆë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘... ì´ ì‘ì—…ì€ ë‹¤ì†Œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                # ë¶„ì„ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ì„¤ì •
                end_date_obj = selected_date
                start_date_obj = end_date_obj - timedelta(days=7)
                
                start_date_str = start_date_obj.strftime("%Y-%m-%d")
                end_date_str = end_date_obj.strftime("%Y-%m-%d")
                
                # ì´ìŠˆ ë¶„ì„ ì‹¤í–‰
                analysis_result = news_system.analyze_issue(
                    issue=selected_issue,
                    start_date=start_date_str,
                    end_date=end_date_str,
                    days_to_analyze=days_to_analyze
                )
                
                # ë¶„ì„ ê²°ê³¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.analysis_result = analysis_result
        
        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if "analysis_result" in st.session_state:
            analysis_result = st.session_state.analysis_result
            
            # ë¶„ì„ ê²°ê³¼ íƒ­ ìƒì„±
            analysis_tab1, analysis_tab2, analysis_tab3, analysis_tab4 = st.tabs([
                "ğŸ“° ê´€ë ¨ ê¸°ì‚¬", "ğŸ”‘ í‚¤ì›Œë“œ ë¶„ì„", "ğŸ“ˆ ì‹œê°„ë³„ ì¶”ì´", "ğŸ” í´ëŸ¬ìŠ¤í„° ë¶„ì„"
            ])
            
            # íƒ­ 1: ê´€ë ¨ ê¸°ì‚¬
            with analysis_tab1:
                st.subheader("ê´€ë ¨ ê¸°ì‚¬ ëª©ë¡")
                
                related_news = analysis_result.get("related_news", [])
                
                if not related_news:
                    st.info("ê´€ë ¨ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ê¸°ì‚¬ ì •ë ¬ (ìµœì‹ ìˆœ)
                    sorted_news = sorted(
                        related_news,
                        key=lambda x: x.get("published_at", ""),
                        reverse=True
                    )
                    
                    # ê´€ë ¨ ê¸°ì‚¬ í‘œì‹œ
                    for i, news in enumerate(sorted_news):
                        with st.expander(f"{i+1}. {news.get('title', 'ì œëª© ì—†ìŒ')} ({news.get('provider', 'ì¶œì²˜ ë¯¸ìƒ')})"):
                            # ë°œí–‰ ì •ë³´
                            st.write(f"*ì¶œì²˜: {news.get('provider', 'ì¶œì²˜ ë¯¸ìƒ')} | ë°œí–‰: {news.get('published_at', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')[:10]} | ê¸°ì: {news.get('byline', 'ì •ë³´ ì—†ìŒ')}*")
                            
                            # í•˜ì´ë¼ì´íŠ¸ ë˜ëŠ” ìš”ì•½
                            if "hilight" in news:
                                st.write("**í•˜ì´ë¼ì´íŠ¸:**")
                                st.write(news.get("hilight", ""))
                            
                            # ë‚´ìš© ìš”ì•½
                            if "content" in news:
                                st.write("**ë‚´ìš© ìš”ì•½:**")
                                summary = news_system.summarize_article(news.get("content", ""))
                                st.write(summary)
                            
                            # ì „ì²´ ë‚´ìš© ë³´ê¸° ì˜µì…˜
                            if "content" in news and st.checkbox(f"ì „ì²´ ë‚´ìš© ë³´ê¸° #{i+1}", key=f"show_content_{i}"):
                                st.write("**ì „ì²´ ë‚´ìš©:**")
                                st.write(news.get("content", ""))
            
            # íƒ­ 2: í‚¤ì›Œë“œ ë¶„ì„
            with analysis_tab2:
                st.subheader("í‚¤ì›Œë“œ ë¶„ì„")
                
                # ì´ìŠˆ í‚¤ì›Œë“œ í‘œì‹œ
                st.write("**ì´ìŠˆ í‚¤ì›Œë“œ:**")
                st.write(", ".join(keywords))
                
                # ì¶”ì¶œëœ í‚¤ì›Œë“œ í‘œì‹œ
                extracted_keywords = analysis_result.get("keywords", [])
                
                if extracted_keywords:
                    st.write("**ì¶”ì¶œëœ í‚¤ì›Œë“œ:**")
                    st.write(", ".join(extracted_keywords[:20]))
                
                # ì—°ê´€ì–´ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                wordcloud_data = analysis_result.get("wordcloud", [])
                
                if wordcloud_data:
                    st.write("**ì—°ê´€ì–´ ë¶„ì„ ê²°ê³¼:**")
                    
                    # ì—°ê´€ì–´ í‘œ í‘œì‹œ
                    wordcloud_df = pd.DataFrame([
                        {"í‚¤ì›Œë“œ": item.get("name", ""), "ì¤‘ìš”ë„": round(item.get("weight", 0), 2)}
                        for item in wordcloud_data
                    ])
                    
                    st.dataframe(wordcloud_df, use_container_width=True)
                    
                    # ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„± ë° í‘œì‹œ
                    st.write("**ì›Œë“œ í´ë¼ìš°ë“œ:**")
                    wordcloud = news_system.create_wordcloud_image(wordcloud_data)
                    
                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.imshow(wordcloud, interpolation='bilinear')
                    ax.axis("off")
                    st.pyplot(fig)
                else:
                    st.info("ì—°ê´€ì–´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # íƒ­ 3: ì‹œê°„ë³„ ì¶”ì´
            with analysis_tab3:
                st.subheader("ì‹œê°„ë³„ í‚¤ì›Œë“œ ì¶”ì´")
                
                timeline_data = analysis_result.get("timeline", {})
                
                if timeline_data and "time_line" in timeline_data and timeline_data["time_line"]:
                    # íƒ€ì„ë¼ì¸ ë°ì´í„° í‘œì‹œ
                    st.write("**ê¸°ê°„ë³„ ì–¸ê¸‰ íšŸìˆ˜:**")
                    
                    # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° í‘œì‹œ
                    timeline_df = pd.DataFrame([
                        {"ë‚ ì§œ": news_system._format_date(item.get("label", "")), "ì–¸ê¸‰ íšŸìˆ˜": item.get("hits", 0)}
                        for item in timeline_data["time_line"]
                    ])
                    
                    st.dataframe(timeline_df, use_container_width=True)
                    
                    # íƒ€ì„ë¼ì¸ ì°¨íŠ¸ ìƒì„± ë° í‘œì‹œ
                    st.write("**í‚¤ì›Œë“œ ì¶”ì´ ì°¨íŠ¸:**")
                    timeline_chart = news_system.create_timeline_chart(timeline_data)
                    st.pyplot(timeline_chart)
                else:
                    st.info("ì‹œê°„ë³„ ì¶”ì´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # íƒ­ 4: í´ëŸ¬ìŠ¤í„° ë¶„ì„
            with analysis_tab4:
                st.subheader("ë‰´ìŠ¤ í´ëŸ¬ìŠ¤í„° ë¶„ì„")
                
                related_news = analysis_result.get("related_news", [])
                
                if related_news:
                    # ë‰´ìŠ¤ í´ëŸ¬ìŠ¤í„°ë§
                    news_clusters = news_system.cluster_news(related_news)
                    
                    if news_clusters:
                        # í´ëŸ¬ìŠ¤í„° í‘œì‹œ
                        for cluster_name, cluster_news in news_clusters.items():
                            with st.expander(f"í´ëŸ¬ìŠ¤í„°: {cluster_name} ({len(cluster_news)}ê°œ ê¸°ì‚¬)"):
                                # í´ëŸ¬ìŠ¤í„° ë‚´ ê¸°ì‚¬ ëª©ë¡
                                for i, news in enumerate(cluster_news):
                                    st.write(f"**{i+1}. {news.get('title', 'ì œëª© ì—†ìŒ')}**")
                                    st.write(f"*ì¶œì²˜: {news.get('provider', 'ì¶œì²˜ ë¯¸ìƒ')} | ë°œí–‰: {news.get('published_at', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')[:10]}*")
                                    
                                    # í•˜ì´ë¼ì´íŠ¸ ë˜ëŠ” ìš”ì•½
                                    if "hilight" in news:
                                        st.write(news.get("hilight", ""))
                                    
                                    st.write("---")
                    else:
                        st.info("í´ëŸ¬ìŠ¤í„° ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("í´ëŸ¬ìŠ¤í„° ë¶„ì„ì„ ìœ„í•œ ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # íƒ­ 3: ê³¼ê±° ë°ì´í„° ë¹„êµ
    with tab3:
        st.header("ğŸ“Š ê³¼ê±° ë°ì´í„° ë¹„êµ")
        
        # ì„¸ì…˜ ìƒíƒœì—ì„œ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        if "analysis_result" in st.session_state:
            analysis_result = st.session_state.analysis_result
            
            # ê³¼ê±° ë°ì´í„° ë¹„êµ ê²°ê³¼ í‘œì‹œ
            historical_comparison = analysis_result.get("historical_comparison", [])
            
            if historical_comparison:
                for period_data in historical_comparison:
                    period = period_data.get("period", "")
                    news_list = period_data.get("news", [])
                    
                    st.subheader(f"{period} ê´€ë ¨ ê¸°ì‚¬ ({len(news_list)}ê°œ)")
                    
                    if news_list:
                        # ê¸°ì‚¬ ëª©ë¡ í‘œì‹œ
                        for i, news in enumerate(news_list):
                            st.write(f"**{i+1}. {news.get('title', 'ì œëª© ì—†ìŒ')}**")
                            st.write(f"*ì¶œì²˜: {news.get('provider', 'ì¶œì²˜ ë¯¸ìƒ')} | ë°œí–‰: {news.get('published_at', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')[:10]}*")
                            st.write("---")
                    else:
                        st.info(f"{period}ì— ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ê³¼ê±° ë°ì´í„° ë¹„êµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì´ìŠˆë¥¼ ë¨¼ì € ë¶„ì„í•´ì£¼ì„¸ìš”. 'ì´ìŠˆ ë¶„ì„' íƒ­ì—ì„œ ì´ìŠˆë¥¼ ì„ íƒí•˜ê³  ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
    
    # í‘¸í„°
    st.markdown("---")
    st.caption("Â© 2025 ë‰´ìŠ¤ ì´ìŠˆ ë¶„ì„ ì‹œìŠ¤í…œ | ë¹…ì¹´ì¸ì¦ˆ API ê¸°ë°˜")

if __name__ == "__main__":
    main()